{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1718077625229,"user":{"displayName":"이도현","userId":"02134394201878625870"},"user_tz":-540},"id":"kwxuBAj7YAMN"},"outputs":[],"source":["# 필요 라이브러리 import\n","import os, sys\n","import urllib.request\n","import random\n","import time\n","import gc\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torchvision\n","import torchvision.models as models\n","from torchvision import datasets, transforms\n","\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchsummary import summary\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from PIL import Image\n","from tqdm import tqdm\n","from timm import create_model"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1718077337671,"user":{"displayName":"이도현","userId":"02134394201878625870"},"user_tz":-540},"id":"z4Bgd947YAMQ"},"outputs":[],"source":["# 데이터 경로 및 SEED 설정\n","DATA_DIR = \"dataset\"\n","SEED = 0xC0FFEE     # 12648430\n","\n","# 재현성을 위한 시드 고정\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"rE9tzwpwYAMR"},"source":["# 데이터 로드"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":571,"status":"ok","timestamp":1718077349105,"user":{"displayName":"이도현","userId":"02134394201878625870"},"user_tz":-540},"id":"eqLZ70qoYAMS"},"outputs":[],"source":["# 이미지 형태 확인\n","transform = transforms.Compose([\n","    transforms.Resize((150, 150)),\n","    transforms.ToTensor(),\n","])\n","dataset = datasets.ImageFolder(root=\"dataset/trainset\", transform=transform)\n","loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=4)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1504,"status":"ok","timestamp":1718077352892,"user":{"displayName":"이도현","userId":"02134394201878625870"},"user_tz":-540},"id":"UZQIosaTYAMT","outputId":"1cc7c002-dc4f-4f6d-cb20-bceffbbbaa16"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([128, 3, 150, 150]) torch.Size([128])\n"]}],"source":["x, y = next(iter(loader))\n","print(x.shape, y.shape)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"H4zLr3bqYAMU"},"outputs":[],"source":["# 이미지 전처리 정의\n","train_transform = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=3),  # 3채널로 변경\n","    transforms.Resize((224, 224)),                # 224x224로 리사이즈\n","    transforms.RandomHorizontalFlip(),            # 50% 확률로 이미지 좌우 반전\n","    transforms.RandomVerticalFlip(),              # 50% 확률로 이미지 상하 반전\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])               # 정규화\n","    ])\n","\n","val_transform = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=3),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","# ImageFolder를 사용하여 데이터셋 만들기\n","original_dataset = datasets.ImageFolder(root=\"dataset/trainset\")\n","\n","# train/validation 분리\n","train_size = len(original_dataset) - 200\n","val_size = 200\n","train_dataset, val_dataset = random_split(original_dataset, [train_size, val_size])\n","\n","# transform 적용\n","train_dataset.dataset.transform = train_transform\n","val_dataset.dataset.transform = val_transform\n","\n","# DataLoader 인스턴스 생성\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=8)\n","validation_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=8)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"C2tBwAIyYAMU","outputId":"71838104-94bf-4526-93ab-6a229c5d63a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 224, 224]) torch.Size([16])\n","torch.Size([1, 3, 224, 224]) torch.Size([1])\n"]}],"source":["# 데이터 형태 확인\n","x, y = next(iter(train_loader))\n","print(x.shape, y.shape)\n","\n","x, y = next(iter(validation_loader))\n","print(x.shape, y.shape)"]},{"cell_type":"markdown","metadata":{"id":"4a0ZrHwZYAMV"},"source":["# Label 확인"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"IakgIALLYAMV","outputId":"819bb66f-d3b1-4eea-c389-03007cffb62a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['aphids', 'armyworm', 'blisterbeetle', 'cicadellidae', 'cornborer', 'cricket', 'delicatula', 'limacodidae', 'miridae', 'viridis']\n","{0: 'aphids', 1: 'armyworm', 2: 'blisterbeetle', 3: 'cicadellidae', 4: 'cornborer', 5: 'cricket', 6: 'delicatula', 7: 'limacodidae', 8: 'miridae', 9: 'viridis'}\n"]}],"source":["classes = original_dataset.classes\n","print(classes)\n","\n","idx_to_class = {v: k for k, v in original_dataset.class_to_idx.items()}\n","print(idx_to_class)"]},{"cell_type":"markdown","metadata":{"id":"2HApjpMIYAMW"},"source":["# 모델 정의"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VJbfuDQWYAMW","outputId":"25383b3c-067e-4b02-d8b3-911a3fd7add2"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["# CUDA 사용 가능 여부 확인\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2Q7ZQBPFYAMX"},"outputs":[],"source":["# 전이학습 모델\n","class VGG16(nn.Module):\n","    def __init__(self, num_classes):\n","        super(VGG16, self).__init__()\n","        # VGG16 모델 정의\n","        self.vgg16 = create_model('vgg16', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.vgg16(x)\n","\n","\n","class VGG19(nn.Module):\n","    def __init__(self, num_classes):\n","        super(VGG19, self).__init__()\n","        # VGG19 모델 정의\n","        self.vgg19 = create_model('vgg19', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.vgg19(x)\n","\n","\n","class ResNet18(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet18, self).__init__()\n","        # ResNet-18 모델 정의\n","        self.resnet = create_model('resnet18', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.resnet(x)\n","\n","\n","class ResNet34(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet34, self).__init__()\n","        # ResNet-34 모델 정의\n","        self.resnet = create_model('resnet34', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.resnet(x)\n","\n","\n","class ResNet50(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet50, self).__init__()\n","        # ResNet-50 모델 정의\n","        self.resnet = create_model('resnet50', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.resnet(x)\n","\n","\n","class ResNet101(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet101, self).__init__()\n","        # ResNet-101 모델 정의\n","        self.resnet = create_model('resnet101', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.resnet(x)\n","\n","\n","class WideResNet50_2(nn.Module):\n","    def __init__(self, num_classes):\n","        super(WideResNet50_2, self).__init__()\n","        # WideResNet-50-2 모델 정의\n","        self.wide_resnet = create_model('wide_resnet50_2', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.wide_resnet(x)\n","\n","\n","class WideResNet101_2(nn.Module):\n","    def __init__(self, num_classes):\n","        super(WideResNet101_2, self).__init__()\n","        # WideResNet-101-2 모델 정의\n","        self.wide_resnet = create_model('wide_resnet101_2', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.wide_resnet(x)\n","\n","\n","#-----------------Transformer 계열------------------------------------------------------------------------\n","class VitModel(nn.Module):\n","    def __init__(self, num_classes):\n","        super(VitModel, self).__init__()\n","        self.vit = create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.vit(x)\n","\n","\n","class SwinModel(nn.Module):\n","    def __init__(self, num_classes):\n","        super(SwinModel, self).__init__()\n","        self.swin = create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.swin(x)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"o_-EFkSgYAMY"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a11da54255914309ad685b667a1c01d6","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/508M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\prohe\\.cache\\huggingface\\hub\\models--timm--wide_resnet101_2.tv_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n"]}],"source":["#model = VGG16(num_classes=len(classes)).to(device)\n","#model = VGG19(num_classes=len(classes)).to(device)\n","#model = ResNet18(num_classes=len(classes)).to(device)\n","#model = ResNet34(num_classes=len(classes)).to(device)\n","model = ResNet50(num_classes=len(classes)).to(device)\n","#model = ResNet101(num_classes=len(classes)).to(device)\n","#model = WideResNet50_2(num_classes=len(classes)).to(device)\n","#model = WideResNet101_2(num_classes=len(classes)).to(device)\n","#model = VitModel(num_classes=len(classes)).to(device)\n","#model = SwinModel(num_classes=len(classes)).to(device)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"iO7AqhZBYAMY","outputId":"710d47e9-b364-4e53-d71b-4ec34a402089"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5          [-1, 128, 56, 56]           8,192\n","       BatchNorm2d-6          [-1, 128, 56, 56]             256\n","              ReLU-7          [-1, 128, 56, 56]               0\n","            Conv2d-8          [-1, 128, 56, 56]         147,456\n","       BatchNorm2d-9          [-1, 128, 56, 56]             256\n","         Identity-10          [-1, 128, 56, 56]               0\n","             ReLU-11          [-1, 128, 56, 56]               0\n","         Identity-12          [-1, 128, 56, 56]               0\n","           Conv2d-13          [-1, 256, 56, 56]          32,768\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","           Conv2d-15          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-16          [-1, 256, 56, 56]             512\n","             ReLU-17          [-1, 256, 56, 56]               0\n","       Bottleneck-18          [-1, 256, 56, 56]               0\n","           Conv2d-19          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-20          [-1, 128, 56, 56]             256\n","             ReLU-21          [-1, 128, 56, 56]               0\n","           Conv2d-22          [-1, 128, 56, 56]         147,456\n","      BatchNorm2d-23          [-1, 128, 56, 56]             256\n","         Identity-24          [-1, 128, 56, 56]               0\n","             ReLU-25          [-1, 128, 56, 56]               0\n","         Identity-26          [-1, 128, 56, 56]               0\n","           Conv2d-27          [-1, 256, 56, 56]          32,768\n","      BatchNorm2d-28          [-1, 256, 56, 56]             512\n","             ReLU-29          [-1, 256, 56, 56]               0\n","       Bottleneck-30          [-1, 256, 56, 56]               0\n","           Conv2d-31          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-32          [-1, 128, 56, 56]             256\n","             ReLU-33          [-1, 128, 56, 56]               0\n","           Conv2d-34          [-1, 128, 56, 56]         147,456\n","      BatchNorm2d-35          [-1, 128, 56, 56]             256\n","         Identity-36          [-1, 128, 56, 56]               0\n","             ReLU-37          [-1, 128, 56, 56]               0\n","         Identity-38          [-1, 128, 56, 56]               0\n","           Conv2d-39          [-1, 256, 56, 56]          32,768\n","      BatchNorm2d-40          [-1, 256, 56, 56]             512\n","             ReLU-41          [-1, 256, 56, 56]               0\n","       Bottleneck-42          [-1, 256, 56, 56]               0\n","           Conv2d-43          [-1, 256, 56, 56]          65,536\n","      BatchNorm2d-44          [-1, 256, 56, 56]             512\n","             ReLU-45          [-1, 256, 56, 56]               0\n","           Conv2d-46          [-1, 256, 28, 28]         589,824\n","      BatchNorm2d-47          [-1, 256, 28, 28]             512\n","         Identity-48          [-1, 256, 28, 28]               0\n","             ReLU-49          [-1, 256, 28, 28]               0\n","         Identity-50          [-1, 256, 28, 28]               0\n","           Conv2d-51          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-52          [-1, 512, 28, 28]           1,024\n","           Conv2d-53          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-54          [-1, 512, 28, 28]           1,024\n","             ReLU-55          [-1, 512, 28, 28]               0\n","       Bottleneck-56          [-1, 512, 28, 28]               0\n","           Conv2d-57          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-58          [-1, 256, 28, 28]             512\n","             ReLU-59          [-1, 256, 28, 28]               0\n","           Conv2d-60          [-1, 256, 28, 28]         589,824\n","      BatchNorm2d-61          [-1, 256, 28, 28]             512\n","         Identity-62          [-1, 256, 28, 28]               0\n","             ReLU-63          [-1, 256, 28, 28]               0\n","         Identity-64          [-1, 256, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-70          [-1, 256, 28, 28]             512\n","             ReLU-71          [-1, 256, 28, 28]               0\n","           Conv2d-72          [-1, 256, 28, 28]         589,824\n","      BatchNorm2d-73          [-1, 256, 28, 28]             512\n","         Identity-74          [-1, 256, 28, 28]               0\n","             ReLU-75          [-1, 256, 28, 28]               0\n","         Identity-76          [-1, 256, 28, 28]               0\n","           Conv2d-77          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-78          [-1, 512, 28, 28]           1,024\n","             ReLU-79          [-1, 512, 28, 28]               0\n","       Bottleneck-80          [-1, 512, 28, 28]               0\n","           Conv2d-81          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-82          [-1, 256, 28, 28]             512\n","             ReLU-83          [-1, 256, 28, 28]               0\n","           Conv2d-84          [-1, 256, 28, 28]         589,824\n","      BatchNorm2d-85          [-1, 256, 28, 28]             512\n","         Identity-86          [-1, 256, 28, 28]               0\n","             ReLU-87          [-1, 256, 28, 28]               0\n","         Identity-88          [-1, 256, 28, 28]               0\n","           Conv2d-89          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-90          [-1, 512, 28, 28]           1,024\n","             ReLU-91          [-1, 512, 28, 28]               0\n","       Bottleneck-92          [-1, 512, 28, 28]               0\n","           Conv2d-93          [-1, 512, 28, 28]         262,144\n","      BatchNorm2d-94          [-1, 512, 28, 28]           1,024\n","             ReLU-95          [-1, 512, 28, 28]               0\n","           Conv2d-96          [-1, 512, 14, 14]       2,359,296\n","      BatchNorm2d-97          [-1, 512, 14, 14]           1,024\n","         Identity-98          [-1, 512, 14, 14]               0\n","             ReLU-99          [-1, 512, 14, 14]               0\n","        Identity-100          [-1, 512, 14, 14]               0\n","          Conv2d-101         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-102         [-1, 1024, 14, 14]           2,048\n","          Conv2d-103         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-104         [-1, 1024, 14, 14]           2,048\n","            ReLU-105         [-1, 1024, 14, 14]               0\n","      Bottleneck-106         [-1, 1024, 14, 14]               0\n","          Conv2d-107          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-108          [-1, 512, 14, 14]           1,024\n","            ReLU-109          [-1, 512, 14, 14]               0\n","          Conv2d-110          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-111          [-1, 512, 14, 14]           1,024\n","        Identity-112          [-1, 512, 14, 14]               0\n","            ReLU-113          [-1, 512, 14, 14]               0\n","        Identity-114          [-1, 512, 14, 14]               0\n","          Conv2d-115         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-116         [-1, 1024, 14, 14]           2,048\n","            ReLU-117         [-1, 1024, 14, 14]               0\n","      Bottleneck-118         [-1, 1024, 14, 14]               0\n","          Conv2d-119          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-120          [-1, 512, 14, 14]           1,024\n","            ReLU-121          [-1, 512, 14, 14]               0\n","          Conv2d-122          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-123          [-1, 512, 14, 14]           1,024\n","        Identity-124          [-1, 512, 14, 14]               0\n","            ReLU-125          [-1, 512, 14, 14]               0\n","        Identity-126          [-1, 512, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-132          [-1, 512, 14, 14]           1,024\n","            ReLU-133          [-1, 512, 14, 14]               0\n","          Conv2d-134          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-135          [-1, 512, 14, 14]           1,024\n","        Identity-136          [-1, 512, 14, 14]               0\n","            ReLU-137          [-1, 512, 14, 14]               0\n","        Identity-138          [-1, 512, 14, 14]               0\n","          Conv2d-139         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-140         [-1, 1024, 14, 14]           2,048\n","            ReLU-141         [-1, 1024, 14, 14]               0\n","      Bottleneck-142         [-1, 1024, 14, 14]               0\n","          Conv2d-143          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-144          [-1, 512, 14, 14]           1,024\n","            ReLU-145          [-1, 512, 14, 14]               0\n","          Conv2d-146          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-147          [-1, 512, 14, 14]           1,024\n","        Identity-148          [-1, 512, 14, 14]               0\n","            ReLU-149          [-1, 512, 14, 14]               0\n","        Identity-150          [-1, 512, 14, 14]               0\n","          Conv2d-151         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-152         [-1, 1024, 14, 14]           2,048\n","            ReLU-153         [-1, 1024, 14, 14]               0\n","      Bottleneck-154         [-1, 1024, 14, 14]               0\n","          Conv2d-155          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-156          [-1, 512, 14, 14]           1,024\n","            ReLU-157          [-1, 512, 14, 14]               0\n","          Conv2d-158          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-159          [-1, 512, 14, 14]           1,024\n","        Identity-160          [-1, 512, 14, 14]               0\n","            ReLU-161          [-1, 512, 14, 14]               0\n","        Identity-162          [-1, 512, 14, 14]               0\n","          Conv2d-163         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-164         [-1, 1024, 14, 14]           2,048\n","            ReLU-165         [-1, 1024, 14, 14]               0\n","      Bottleneck-166         [-1, 1024, 14, 14]               0\n","          Conv2d-167          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-168          [-1, 512, 14, 14]           1,024\n","            ReLU-169          [-1, 512, 14, 14]               0\n","          Conv2d-170          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-171          [-1, 512, 14, 14]           1,024\n","        Identity-172          [-1, 512, 14, 14]               0\n","            ReLU-173          [-1, 512, 14, 14]               0\n","        Identity-174          [-1, 512, 14, 14]               0\n","          Conv2d-175         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-176         [-1, 1024, 14, 14]           2,048\n","            ReLU-177         [-1, 1024, 14, 14]               0\n","      Bottleneck-178         [-1, 1024, 14, 14]               0\n","          Conv2d-179          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-180          [-1, 512, 14, 14]           1,024\n","            ReLU-181          [-1, 512, 14, 14]               0\n","          Conv2d-182          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-183          [-1, 512, 14, 14]           1,024\n","        Identity-184          [-1, 512, 14, 14]               0\n","            ReLU-185          [-1, 512, 14, 14]               0\n","        Identity-186          [-1, 512, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-192          [-1, 512, 14, 14]           1,024\n","            ReLU-193          [-1, 512, 14, 14]               0\n","          Conv2d-194          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-195          [-1, 512, 14, 14]           1,024\n","        Identity-196          [-1, 512, 14, 14]               0\n","            ReLU-197          [-1, 512, 14, 14]               0\n","        Identity-198          [-1, 512, 14, 14]               0\n","          Conv2d-199         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-200         [-1, 1024, 14, 14]           2,048\n","            ReLU-201         [-1, 1024, 14, 14]               0\n","      Bottleneck-202         [-1, 1024, 14, 14]               0\n","          Conv2d-203          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-204          [-1, 512, 14, 14]           1,024\n","            ReLU-205          [-1, 512, 14, 14]               0\n","          Conv2d-206          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-207          [-1, 512, 14, 14]           1,024\n","        Identity-208          [-1, 512, 14, 14]               0\n","            ReLU-209          [-1, 512, 14, 14]               0\n","        Identity-210          [-1, 512, 14, 14]               0\n","          Conv2d-211         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-212         [-1, 1024, 14, 14]           2,048\n","            ReLU-213         [-1, 1024, 14, 14]               0\n","      Bottleneck-214         [-1, 1024, 14, 14]               0\n","          Conv2d-215          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-216          [-1, 512, 14, 14]           1,024\n","            ReLU-217          [-1, 512, 14, 14]               0\n","          Conv2d-218          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-219          [-1, 512, 14, 14]           1,024\n","        Identity-220          [-1, 512, 14, 14]               0\n","            ReLU-221          [-1, 512, 14, 14]               0\n","        Identity-222          [-1, 512, 14, 14]               0\n","          Conv2d-223         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-224         [-1, 1024, 14, 14]           2,048\n","            ReLU-225         [-1, 1024, 14, 14]               0\n","      Bottleneck-226         [-1, 1024, 14, 14]               0\n","          Conv2d-227          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-228          [-1, 512, 14, 14]           1,024\n","            ReLU-229          [-1, 512, 14, 14]               0\n","          Conv2d-230          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-231          [-1, 512, 14, 14]           1,024\n","        Identity-232          [-1, 512, 14, 14]               0\n","            ReLU-233          [-1, 512, 14, 14]               0\n","        Identity-234          [-1, 512, 14, 14]               0\n","          Conv2d-235         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-236         [-1, 1024, 14, 14]           2,048\n","            ReLU-237         [-1, 1024, 14, 14]               0\n","      Bottleneck-238         [-1, 1024, 14, 14]               0\n","          Conv2d-239          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-240          [-1, 512, 14, 14]           1,024\n","            ReLU-241          [-1, 512, 14, 14]               0\n","          Conv2d-242          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-243          [-1, 512, 14, 14]           1,024\n","        Identity-244          [-1, 512, 14, 14]               0\n","            ReLU-245          [-1, 512, 14, 14]               0\n","        Identity-246          [-1, 512, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-252          [-1, 512, 14, 14]           1,024\n","            ReLU-253          [-1, 512, 14, 14]               0\n","          Conv2d-254          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-255          [-1, 512, 14, 14]           1,024\n","        Identity-256          [-1, 512, 14, 14]               0\n","            ReLU-257          [-1, 512, 14, 14]               0\n","        Identity-258          [-1, 512, 14, 14]               0\n","          Conv2d-259         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-260         [-1, 1024, 14, 14]           2,048\n","            ReLU-261         [-1, 1024, 14, 14]               0\n","      Bottleneck-262         [-1, 1024, 14, 14]               0\n","          Conv2d-263          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-264          [-1, 512, 14, 14]           1,024\n","            ReLU-265          [-1, 512, 14, 14]               0\n","          Conv2d-266          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-267          [-1, 512, 14, 14]           1,024\n","        Identity-268          [-1, 512, 14, 14]               0\n","            ReLU-269          [-1, 512, 14, 14]               0\n","        Identity-270          [-1, 512, 14, 14]               0\n","          Conv2d-271         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-272         [-1, 1024, 14, 14]           2,048\n","            ReLU-273         [-1, 1024, 14, 14]               0\n","      Bottleneck-274         [-1, 1024, 14, 14]               0\n","          Conv2d-275          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-276          [-1, 512, 14, 14]           1,024\n","            ReLU-277          [-1, 512, 14, 14]               0\n","          Conv2d-278          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-279          [-1, 512, 14, 14]           1,024\n","        Identity-280          [-1, 512, 14, 14]               0\n","            ReLU-281          [-1, 512, 14, 14]               0\n","        Identity-282          [-1, 512, 14, 14]               0\n","          Conv2d-283         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-284         [-1, 1024, 14, 14]           2,048\n","            ReLU-285         [-1, 1024, 14, 14]               0\n","      Bottleneck-286         [-1, 1024, 14, 14]               0\n","          Conv2d-287          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-288          [-1, 512, 14, 14]           1,024\n","            ReLU-289          [-1, 512, 14, 14]               0\n","          Conv2d-290          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-291          [-1, 512, 14, 14]           1,024\n","        Identity-292          [-1, 512, 14, 14]               0\n","            ReLU-293          [-1, 512, 14, 14]               0\n","        Identity-294          [-1, 512, 14, 14]               0\n","          Conv2d-295         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-296         [-1, 1024, 14, 14]           2,048\n","            ReLU-297         [-1, 1024, 14, 14]               0\n","      Bottleneck-298         [-1, 1024, 14, 14]               0\n","          Conv2d-299          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-300          [-1, 512, 14, 14]           1,024\n","            ReLU-301          [-1, 512, 14, 14]               0\n","          Conv2d-302          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-303          [-1, 512, 14, 14]           1,024\n","        Identity-304          [-1, 512, 14, 14]               0\n","            ReLU-305          [-1, 512, 14, 14]               0\n","        Identity-306          [-1, 512, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-315          [-1, 512, 14, 14]           1,024\n","        Identity-316          [-1, 512, 14, 14]               0\n","            ReLU-317          [-1, 512, 14, 14]               0\n","        Identity-318          [-1, 512, 14, 14]               0\n","          Conv2d-319         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-320         [-1, 1024, 14, 14]           2,048\n","            ReLU-321         [-1, 1024, 14, 14]               0\n","      Bottleneck-322         [-1, 1024, 14, 14]               0\n","          Conv2d-323          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-324          [-1, 512, 14, 14]           1,024\n","            ReLU-325          [-1, 512, 14, 14]               0\n","          Conv2d-326          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-327          [-1, 512, 14, 14]           1,024\n","        Identity-328          [-1, 512, 14, 14]               0\n","            ReLU-329          [-1, 512, 14, 14]               0\n","        Identity-330          [-1, 512, 14, 14]               0\n","          Conv2d-331         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-332         [-1, 1024, 14, 14]           2,048\n","            ReLU-333         [-1, 1024, 14, 14]               0\n","      Bottleneck-334         [-1, 1024, 14, 14]               0\n","          Conv2d-335          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-336          [-1, 512, 14, 14]           1,024\n","            ReLU-337          [-1, 512, 14, 14]               0\n","          Conv2d-338          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-339          [-1, 512, 14, 14]           1,024\n","        Identity-340          [-1, 512, 14, 14]               0\n","            ReLU-341          [-1, 512, 14, 14]               0\n","        Identity-342          [-1, 512, 14, 14]               0\n","          Conv2d-343         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-344         [-1, 1024, 14, 14]           2,048\n","            ReLU-345         [-1, 1024, 14, 14]               0\n","      Bottleneck-346         [-1, 1024, 14, 14]               0\n","          Conv2d-347          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-348          [-1, 512, 14, 14]           1,024\n","            ReLU-349          [-1, 512, 14, 14]               0\n","          Conv2d-350          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-351          [-1, 512, 14, 14]           1,024\n","        Identity-352          [-1, 512, 14, 14]               0\n","            ReLU-353          [-1, 512, 14, 14]               0\n","        Identity-354          [-1, 512, 14, 14]               0\n","          Conv2d-355         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-356         [-1, 1024, 14, 14]           2,048\n","            ReLU-357         [-1, 1024, 14, 14]               0\n","      Bottleneck-358         [-1, 1024, 14, 14]               0\n","          Conv2d-359          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-360          [-1, 512, 14, 14]           1,024\n","            ReLU-361          [-1, 512, 14, 14]               0\n","          Conv2d-362          [-1, 512, 14, 14]       2,359,296\n","     BatchNorm2d-363          [-1, 512, 14, 14]           1,024\n","        Identity-364          [-1, 512, 14, 14]               0\n","            ReLU-365          [-1, 512, 14, 14]               0\n","        Identity-366          [-1, 512, 14, 14]               0\n","          Conv2d-367         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n","            ReLU-369         [-1, 1024, 14, 14]               0\n","      Bottleneck-370         [-1, 1024, 14, 14]               0\n","          Conv2d-371         [-1, 1024, 14, 14]       1,048,576\n","     BatchNorm2d-372         [-1, 1024, 14, 14]           2,048\n","            ReLU-373         [-1, 1024, 14, 14]               0\n","          Conv2d-374           [-1, 1024, 7, 7]       9,437,184\n","     BatchNorm2d-375           [-1, 1024, 7, 7]           2,048\n","        Identity-376           [-1, 1024, 7, 7]               0\n","            ReLU-377           [-1, 1024, 7, 7]               0\n","        Identity-378           [-1, 1024, 7, 7]               0\n","          Conv2d-379           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-380           [-1, 2048, 7, 7]           4,096\n","          Conv2d-381           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-382           [-1, 2048, 7, 7]           4,096\n","            ReLU-383           [-1, 2048, 7, 7]               0\n","      Bottleneck-384           [-1, 2048, 7, 7]               0\n","          Conv2d-385           [-1, 1024, 7, 7]       2,097,152\n","     BatchNorm2d-386           [-1, 1024, 7, 7]           2,048\n","            ReLU-387           [-1, 1024, 7, 7]               0\n","          Conv2d-388           [-1, 1024, 7, 7]       9,437,184\n","     BatchNorm2d-389           [-1, 1024, 7, 7]           2,048\n","        Identity-390           [-1, 1024, 7, 7]               0\n","            ReLU-391           [-1, 1024, 7, 7]               0\n","        Identity-392           [-1, 1024, 7, 7]               0\n","          Conv2d-393           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-394           [-1, 2048, 7, 7]           4,096\n","            ReLU-395           [-1, 2048, 7, 7]               0\n","      Bottleneck-396           [-1, 2048, 7, 7]               0\n","          Conv2d-397           [-1, 1024, 7, 7]       2,097,152\n","     BatchNorm2d-398           [-1, 1024, 7, 7]           2,048\n","            ReLU-399           [-1, 1024, 7, 7]               0\n","          Conv2d-400           [-1, 1024, 7, 7]       9,437,184\n","     BatchNorm2d-401           [-1, 1024, 7, 7]           2,048\n","        Identity-402           [-1, 1024, 7, 7]               0\n","            ReLU-403           [-1, 1024, 7, 7]               0\n","        Identity-404           [-1, 1024, 7, 7]               0\n","          Conv2d-405           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-406           [-1, 2048, 7, 7]           4,096\n","            ReLU-407           [-1, 2048, 7, 7]               0\n","      Bottleneck-408           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-409           [-1, 2048, 1, 1]               0\n","         Flatten-410                 [-1, 2048]               0\n","SelectAdaptivePool2d-411                 [-1, 2048]               0\n","          Linear-412                   [-1, 10]          20,490\n","          ResNet-413                   [-1, 10]               0\n","================================================================\n","Total params: 124,858,186\n","Trainable params: 124,858,186\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 612.16\n","Params size (MB): 476.30\n","Estimated Total Size (MB): 1089.03\n","----------------------------------------------------------------\n"]}],"source":["# 모델 확인\n","summary(model, (3, 224, 224))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ow7h3KVTYAMY"},"outputs":[],"source":["# 손실 함수와 최적화 함수 정의\n","optimizer = optim.Adam(model.parameters(), lr=1e-6)     # 1e-6 = 0.000001\n","loss_fn = nn.CrossEntropyLoss()     # 다중 클래스 분류 문제이므로 CrossEntropyLoss 사용"]},{"cell_type":"markdown","metadata":{"id":"E8wBrGDpYAMY"},"source":["# 모델 훈련 및 검증"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"PVTETyM2YAMZ"},"outputs":[],"source":["# 학습 함수 정의\n","def fit(model, data_loader, loss_fn, optimizer, device, phase='train'):\n","    # phase에 따라 모델의 모드 설정\n","    if phase == 'train':\n","        model.train()\n","    else:\n","        model.eval()\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","\n","    # tqdm을 사용하여 반복문 진행 상황 시각화\n","    prograss_bar = tqdm(data_loader, leave=False)\n","\n","    # mini-batch 단위 학습 시작\n","    for img, lbl in prograss_bar:\n","        img, lbl = img.to(device), lbl.to(device)\n","\n","        optimizer.zero_grad()       # 누적 Gradient 초기화\n","\n","        # Gradient 계산을 통한 Forward Propagation\n","        with torch.set_grad_enabled(phase == 'train'):\n","            pred = model(img)           # Forward Propagation 수행\n","            loss = loss_fn(pred, lbl)   # 손실 값 계산\n","\n","            if phase == 'train':        # 학습 모드인 경우 Backward Propagation 및 가중치 업데이트 수행\n","                loss.backward()\n","                optimizer.step()\n","\n","        pred = pred.argmax(1)           # pred의 확률값을 클래스 레이블로 변환\n","        running_loss += loss.item()     # 손실 값 누적\n","        running_corrects += torch.sum(pred == lbl.data)    # 정답 수 누적\n","\n","    # 손실 값과 정확도 계산\n","    final_acc = running_corrects / len(data_loader.dataset)\n","    final_loss = running_loss / len(data_loader.dataset)\n","\n","    return final_loss, final_acc"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ptBchdZYYAMZ","outputId":"93b59c43-ebb3-4074-b9b5-03a8e94fc008"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from inf to 0.64788. Saving Model!\n","[Epoch01] time: 4m 18s \t loss: 0.06269, acc: 0.67893 | val_loss: 0.64788, val_acc: 0.78400\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 0.64788 to 0.53782. Saving Model!\n","[Epoch02] time: 4m 15s \t loss: 0.02533, acc: 0.87155 | val_loss: 0.53782, val_acc: 0.81000\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch03] time: 4m 14s \t loss: 0.01292, acc: 0.93340 | val_loss: 0.60826, val_acc: 0.81200\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[12], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 학습 및 검증 단계 진행\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m valid_loss, valid_acc \u001b[38;5;241m=\u001b[39m fit(\n\u001b[0;32m     20\u001b[0m     model, validation_loader, loss_fn, optimizer, device, phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 학습 결과 기록\u001b[39;00m\n","Cell \u001b[1;32mIn[11], line 23\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, data_loader, loss_fn, optimizer, device, phase)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Gradient 계산을 통한 Forward Propagation\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m           \u001b[38;5;66;03m# Forward Propagation 수행\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, lbl)   \u001b[38;5;66;03m# 손실 값 계산\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:        \u001b[38;5;66;03m# 학습 모드인 경우 Backward Propagation 및 가중치 업데이트 수행\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[7], line 74\u001b[0m, in \u001b[0;36mWideResNet50_2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwide_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\timm\\models\\resnet.py:644\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 644\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    645\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\timm\\models\\resnet.py:632\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m--> 632\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m    634\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\timm\\models\\resnet.py:223\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    220\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(x)\n\u001b[0;32m    222\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[1;32m--> 223\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_block(x)\n\u001b[0;32m    225\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact2(x)\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\prohe\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Epoch별 모델 학습\n","num_epochs = 30\n","\n","min_loss = np.inf\n","max_acc = 0.0\n","\n","record_train_loss, record_train_acc = [], []\n","record_valid_loss, record_valid_acc = [], []\n","\n","STATE_DICT_PATH = \"temp_model.pth\"\n","\n","for epoch in range(num_epochs):\n","    start = time.time()\n","\n","    # 학습 및 검증 단계 진행\n","    train_loss, train_acc = fit(\n","        model, train_loader, loss_fn, optimizer, device, phase='train'\n","    )\n","    valid_loss, valid_acc = fit(\n","        model, validation_loader, loss_fn, optimizer, device, phase='valid'\n","    )\n","\n","    # 학습 결과 기록\n","    record_train_loss.append(train_loss)\n","    record_train_acc.append(train_acc)\n","    record_valid_loss.append(valid_loss)\n","    record_valid_acc.append(valid_acc)\n","\n","    # 성능이 좋아질 경우 모델 저장\n","    if valid_loss < min_loss:\n","        print(\n","            f\"[INFO] val_loss has been improved from {min_loss:.5f} to {valid_loss:.5f}. Saving Model!\"\n","        )\n","        min_loss = valid_loss\n","        torch.save(model.state_dict(), STATE_DICT_PATH)\n","\n","    # 학습 시간 및 손실 값, 정확도 출력\n","    time_elapsed = time.time() - start\n","    print(\n","        f\"[Epoch{epoch+1:02d}] time: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s \\t loss: {train_loss:.5f}, acc: {train_acc:.5f} | val_loss: {valid_loss:.5f}, val_acc: {valid_acc:.5f}\"\n","    )"]},{"cell_type":"markdown","metadata":{"id":"aEaZj5u6bW-i"},"source":["# 검증 정확도 확인"]},{"cell_type":"markdown","metadata":{"id":"NvUjCgH1YAMZ"},"source":["> 저장한 모델의 가중치 load"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"alte7hNvYAMZ","outputId":"d50bf8d7-f759-4dc1-a67a-18769d4ac255"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(\"temp_model.pth\"))    # 가장 성능이 좋았던 모델 불러오기"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"T2aimElJYAMa"},"outputs":[],"source":["predictons = []\n","model = model.to(device)\n","model.eval()\n","\n","with torch.no_grad():\n","    running_loss = 0.0\n","    running_corrects = 0\n","\n","    for img, lbl in validation_loader:\n","        img, lbl = img.to(device), lbl.to(device)\n","\n","        pred = model(img)\n","        loss = loss_fn(pred, lbl)\n","\n","        running_loss += loss.item()\n","        running_corrects += torch.sum(pred.argmax(1) == lbl.data)\n","\n","        predictons.extend(pred.argmax(1).cpu().numpy())     # extend: 리스트에 다른 리스트의 요소를 추가할 때 사용\n","\n","    # 손실 값과 정확도 계산\n","    final_acc = running_corrects / len(validation_loader.dataset)\n","    final_loss = running_loss / len(validation_loader.dataset)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"_3FJa-y4YAMa","outputId":"15b872f6-5112-412e-9c15-5c589f76f1c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["<<Final Performances>>  Loss: 1.32185 | Accuracy: 0.52200\n","Prediction Length: 500  |  Prediction Example: [9, 5, 4, 8, 5, 3, 2, 6, 9, 8, 1, 4, 7, 2, 3]\n"]}],"source":["# 결과 확인\n","print(f\"<<Final Performances>>  Loss: {final_loss:.5f} | Accuracy: {final_acc:.5f}\")\n","print(f\"Prediction Length: {len(predictons)}  |  Prediction Example: {predictons[:15]}\")"]},{"cell_type":"markdown","metadata":{"id":"AxQq59naYAMa"},"source":["# 최종 예측 수행"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":444,"status":"ok","timestamp":1718077437636,"user":{"displayName":"이도현","userId":"02134394201878625870"},"user_tz":-540},"id":"sJW4rRZUZSqC","outputId":"1a552313-02a8-4c6c-9645-300ca24b6a2b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FilePath</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>./dataset/problemset/001.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>./dataset/problemset/002.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>./dataset/problemset/003.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>./dataset/problemset/004.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>./dataset/problemset/005.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       FilePath\n","0  ./dataset/problemset/001.jpg\n","1  ./dataset/problemset/002.jpg\n","2  ./dataset/problemset/003.jpg\n","3  ./dataset/problemset/004.jpg\n","4  ./dataset/problemset/005.jpg"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["problem = pd.read_csv(os.path.join(DATA_DIR, \"problem.csv\"))\n","problem.head()"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":402,"status":"ok","timestamp":1718077631351,"user":{"displayName":"이도현","userId":"02134394201878625870"},"user_tz":-540},"id":"PoOzktPFZS8f"},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, dataframe, transform=None):\n","        self.dataframe = dataframe\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.dataframe.iloc[idx, 0]  # 'FilePath' 열에서 이미지 경로 가져오기\n","        image = Image.open(img_path).convert(\"L\")  # 이미지를 흑백으로 로드\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image\n","\n","\n","# 이미지를 불러올 때 적용할 전처리 정의: resize, to tensor\n","problem_transform = transforms.Compose(\n","    [\n","        transforms.Grayscale(num_output_channels=3),  # 흑백 이미지 load (채널 3개)\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ]\n",")\n","\n","\n","# 커스텀 데이터셋 인스턴스 생성\n","custom_dataset = CustomImageDataset(dataframe=problem, transform=problem_transform)\n","\n","# DataLoader 인스턴스 생성\n","problem_loader = DataLoader(custom_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1718077686369,"user":{"displayName":"이도현","userId":"02134394201878625870"},"user_tz":-540},"id":"PLb8ZX0VaEdG","outputId":"6cf9cbb5-94d4-47a5-9d00-dd3d4fa734e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 3, 224, 224])\n"]}],"source":["x= next(iter(problem_loader))\n","print(x.shape)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"1NcLavk4ZY50"},"outputs":[],"source":["predictions = []\n","\n","# 검증모드 진입\n","model.eval()\n","\n","with torch.no_grad():\n","    # loss 초기화\n","    running_loss = 0\n","    # 정확도 계산\n","    running_acc = 0\n","    for img in problem_loader:\n","        img = img.to(device)\n","\n","        y_hat = model(img)\n","        label = y_hat.argmax(dim=1).detach().item()\n","        predictions.append(label)\n","\n","# 숫자 라벨을 클래스 이름으로 변환\n","your_answer = [idx_to_class[l] for l in predictions]"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"Ivaxf2CgZnie"},"outputs":[],"source":["submission = pd.read_csv(os.path.join(DATA_DIR, \"submission.csv\"))\n","submission[\"Label\"] = your_answer"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FilePath</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>./dataset/problemset/001.jpg</td>\n","      <td>cicadellidae</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>./dataset/problemset/002.jpg</td>\n","      <td>blisterbeetle</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>./dataset/problemset/003.jpg</td>\n","      <td>armyworm</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>./dataset/problemset/004.jpg</td>\n","      <td>cornborer</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>./dataset/problemset/005.jpg</td>\n","      <td>aphids</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>./dataset/problemset/196.jpg</td>\n","      <td>viridis</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>./dataset/problemset/197.jpg</td>\n","      <td>viridis</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>./dataset/problemset/198.jpg</td>\n","      <td>viridis</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>./dataset/problemset/199.jpg</td>\n","      <td>cicadellidae</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>./dataset/problemset/200.jpg</td>\n","      <td>viridis</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 2 columns</p>\n","</div>"],"text/plain":["                         FilePath          Label\n","0    ./dataset/problemset/001.jpg   cicadellidae\n","1    ./dataset/problemset/002.jpg  blisterbeetle\n","2    ./dataset/problemset/003.jpg       armyworm\n","3    ./dataset/problemset/004.jpg      cornborer\n","4    ./dataset/problemset/005.jpg         aphids\n","..                            ...            ...\n","195  ./dataset/problemset/196.jpg        viridis\n","196  ./dataset/problemset/197.jpg        viridis\n","197  ./dataset/problemset/198.jpg        viridis\n","198  ./dataset/problemset/199.jpg   cicadellidae\n","199  ./dataset/problemset/200.jpg        viridis\n","\n","[200 rows x 2 columns]"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["submission"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"bywL52gxZnlC"},"outputs":[],"source":["# 제출 파일 저장\n","submission.to_csv(\"modified_fc_layer_ResNet18.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcEBFrHmZS-x"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"py38","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
