{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline_modeling (baseline_model.csv)\n",
    "> Public Score: 27086.90876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "file_path = os.path.join(os.getcwd(), 'data')\n",
    "train_origin = pd.read_csv(file_path+'\\dataset.csv')\n",
    "test_origin = pd.read_csv(file_path+'\\problem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1340, 24), (130, 23))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_origin.shape, test_origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, valid = train_test_split(train_origin, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1206, 24), (134, 24))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_origin.copy()   # test data 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리를 효율적으로 사용하기 위한 downcast 함수 정의\n",
    "def downcast(df, verbose=True):     # verbose 옵션 추가: (True)인 경우 몇 퍼센트 압축됐는지 출력\n",
    "    start_mem = df.memory_usage().sum() / 1024**2   # 초기 메모리 사용량\n",
    "    for col in df.columns:\n",
    "        dtype_name = df[col].dtype.name\n",
    "        if dtype_name == 'object':\n",
    "            pass\n",
    "        elif dtype_name == 'bool':\n",
    "            df[col] = df[col].astype('int8')\n",
    "        elif dtype_name.startswith('int') or (df[col].round() == df[col]).all():\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    if verbose:\n",
    "        print(f'{(100*(start_mem - end_mem) / start_mem):.1f}% 압축됨')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.5% 압축됨\n",
      "64.5% 압축됨\n",
      "68.7% 압축됨\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1341</td>\n",
       "      <td>11200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Inside</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>1040</td>\n",
       "      <td>1040</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>384</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1342</td>\n",
       "      <td>7200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Corner</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>2000</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1343</td>\n",
       "      <td>16905</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Inside</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1959</td>\n",
       "      <td>1959</td>\n",
       "      <td>1350</td>\n",
       "      <td>1328</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1344</td>\n",
       "      <td>9180</td>\n",
       "      <td>Pave</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1983</td>\n",
       "      <td>1983</td>\n",
       "      <td>840</td>\n",
       "      <td>884</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1983</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1345</td>\n",
       "      <td>7200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Inside</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1920</td>\n",
       "      <td>1996</td>\n",
       "      <td>530</td>\n",
       "      <td>581</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1935</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1466</td>\n",
       "      <td>11478</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Inside</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>1704</td>\n",
       "      <td>1704</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>772</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1467</td>\n",
       "      <td>16321</td>\n",
       "      <td>Pave</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1957</td>\n",
       "      <td>1997</td>\n",
       "      <td>1484</td>\n",
       "      <td>1600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>319</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1468</td>\n",
       "      <td>6324</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Inside</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1927</td>\n",
       "      <td>1950</td>\n",
       "      <td>520</td>\n",
       "      <td>520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1920</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1469</td>\n",
       "      <td>8500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Inside</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1920</td>\n",
       "      <td>1950</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1920</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1470</td>\n",
       "      <td>8544</td>\n",
       "      <td>Pave</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1966</td>\n",
       "      <td>2006</td>\n",
       "      <td>1228</td>\n",
       "      <td>1228</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1966</td>\n",
       "      <td>1</td>\n",
       "      <td>271</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  LotArea Street LotConfig  OverallQual  OverallCond  YearBuilt  \\\n",
       "0    1341    11200   Pave    Inside            5            5       1965   \n",
       "1    1342     7200   Pave    Corner            5            7       1951   \n",
       "2    1343    16905   Pave    Inside            5            6       1959   \n",
       "3    1344     9180   Pave   CulDSac            5            7       1983   \n",
       "4    1345     7200   Pave    Inside            5            7       1920   \n",
       "..    ...      ...    ...       ...          ...          ...        ...   \n",
       "125  1466    11478   Pave    Inside            8            5       2007   \n",
       "126  1467    16321   Pave   CulDSac            5            6       1957   \n",
       "127  1468     6324   Pave    Inside            4            6       1927   \n",
       "128  1469     8500   Pave    Inside            4            4       1920   \n",
       "129  1470     8544   Pave   CulDSac            5            6       1966   \n",
       "\n",
       "     YearRemodAdd  TotalBsmtSF  1stFlrSF  ...  HalfBath  BedroomAbvGr  \\\n",
       "0            1965         1040      1040  ...         0             3   \n",
       "1            2000          900       900  ...         0             3   \n",
       "2            1959         1350      1328  ...         1             2   \n",
       "3            1983          840       884  ...         0             2   \n",
       "4            1996          530       581  ...         0             3   \n",
       "..            ...          ...       ...  ...       ...           ...   \n",
       "125          2008         1704      1704  ...         0             3   \n",
       "126          1997         1484      1600  ...         0             2   \n",
       "127          1950          520       520  ...         0             1   \n",
       "128          1950          649       649  ...         0             3   \n",
       "129          2006         1228      1228  ...         1             3   \n",
       "\n",
       "     KitchenAbvGr  TotRmsAbvGrd  Fireplaces  GarageType  GarageYrBlt  \\\n",
       "0               1             5           0      Detchd         1965   \n",
       "1               1             5           0      Detchd         2005   \n",
       "2               1             5           2      Attchd         1959   \n",
       "3               1             5           0      Attchd         1983   \n",
       "4               1             6           0      Detchd         1935   \n",
       "..            ...           ...         ...         ...          ...   \n",
       "125             1             7           1      Attchd         2008   \n",
       "126             1             6           2      Attchd         1957   \n",
       "127             1             4           0      Detchd         1920   \n",
       "128             1             6           0      Detchd         1920   \n",
       "129             1             6           0      Attchd         1966   \n",
       "\n",
       "     GarageCars GarageArea  YrSold  \n",
       "0             1        384    2008  \n",
       "1             2        576    2010  \n",
       "2             1        308    2007  \n",
       "3             2        504    2007  \n",
       "4             1        288    2007  \n",
       "..          ...        ...     ...  \n",
       "125           3        772    2010  \n",
       "126           1        319    2006  \n",
       "127           1        240    2008  \n",
       "128           1        250    2008  \n",
       "129           1        271    2008  \n",
       "\n",
       "[130 rows x 23 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downcast(train)\n",
    "downcast(valid)\n",
    "downcast(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부 column 제거(Id, GarageCars, GarageYrBlt, TotRmsAbvGrd, TotalBsmtSF)\n",
    "train = train.drop(columns=['Id', 'GarageCars', 'GarageYrBlt', 'TotRmsAbvGrd', 'TotalBsmtSF'])\n",
    "valid = valid.drop(columns=['Id', 'GarageCars', 'GarageYrBlt', 'TotRmsAbvGrd', 'TotalBsmtSF'])\n",
    "test = test.drop(columns=['Id', 'GarageCars', 'GarageYrBlt', 'TotRmsAbvGrd', 'TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.duplicated().sum()\n",
    "\n",
    "# 중복 데이터 제거\n",
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y 분리\n",
    "X_train = train.drop(columns='SalePrice', axis=1)\n",
    "y_train = train['SalePrice']\n",
    "\n",
    "X_valid = valid.drop(columns='SalePrice', axis=1)\n",
    "y_valid = valid['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotArea          0\n",
       "Street           0\n",
       "LotConfig        0\n",
       "OverallQual      0\n",
       "OverallCond      0\n",
       "YearBuilt        0\n",
       "YearRemodAdd     0\n",
       "1stFlrSF         0\n",
       "2ndFlrSF         0\n",
       "GrLivArea        0\n",
       "FullBath         0\n",
       "HalfBath         0\n",
       "BedroomAbvGr     0\n",
       "KitchenAbvGr     0\n",
       "Fireplaces       0\n",
       "GarageType      73\n",
       "GarageArea       0\n",
       "YrSold           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 최빈값 처리\n",
    "train_mode = X_train['GarageType'].mode()[0]\n",
    "X_train['GarageType'] = X_train['GarageType'].fillna(train_mode)\n",
    "X_valid['GarageType'] = X_valid['GarageType'].fillna(train_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum().sum(), X_valid.isnull().sum().sum(), test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1205, 18), (134, 18), (130, 18))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 OHE\n",
    "categorical = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "all_data = pd.concat([X_train, X_valid, test], sort=False)\n",
    "\n",
    "all_data = pd.get_dummies(all_data, columns=categorical)\n",
    "\n",
    "X_train_encoded = all_data[:len(X_train)]\n",
    "X_valid_encoded = all_data[len(X_train):-len(test)]\n",
    "test_encoded = all_data[-len(test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1205, 28), (134, 28), (130, 28))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.shape, X_valid_encoded.shape, test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>...</th>\n",
       "      <th>LotConfig_CulDSac</th>\n",
       "      <th>LotConfig_FR2</th>\n",
       "      <th>LotConfig_FR3</th>\n",
       "      <th>LotConfig_Inside</th>\n",
       "      <th>GarageType_2Types</th>\n",
       "      <th>GarageType_Attchd</th>\n",
       "      <th>GarageType_Basment</th>\n",
       "      <th>GarageType_BuiltIn</th>\n",
       "      <th>GarageType_CarPort</th>\n",
       "      <th>GarageType_Detchd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>15138</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "      <td>1996</td>\n",
       "      <td>1490</td>\n",
       "      <td>1304</td>\n",
       "      <td>2794</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2308</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1974</td>\n",
       "      <td>1974</td>\n",
       "      <td>855</td>\n",
       "      <td>467</td>\n",
       "      <td>1322</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>53107</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1079</td>\n",
       "      <td>874</td>\n",
       "      <td>1953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>11988</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1957</td>\n",
       "      <td>1957</td>\n",
       "      <td>1244</td>\n",
       "      <td>0</td>\n",
       "      <td>1244</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>17871</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1967</td>\n",
       "      <td>1976</td>\n",
       "      <td>1724</td>\n",
       "      <td>0</td>\n",
       "      <td>1724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  1stFlrSF  \\\n",
       "196     15138            8            5       1995          1996      1490   \n",
       "447      2308            6            5       1974          1974       855   \n",
       "339     53107            6            5       1992          1992      1079   \n",
       "464     11988            6            6       1957          1957      1244   \n",
       "1190    17871            6            5       1967          1976      1724   \n",
       "\n",
       "      2ndFlrSF  GrLivArea  FullBath  HalfBath  ...  LotConfig_CulDSac  \\\n",
       "196       1304       2794         2         1  ...              False   \n",
       "447        467       1322         2         1  ...              False   \n",
       "339        874       1953         2         1  ...              False   \n",
       "464          0       1244         1         1  ...              False   \n",
       "1190         0       1724         1         1  ...               True   \n",
       "\n",
       "      LotConfig_FR2  LotConfig_FR3  LotConfig_Inside  GarageType_2Types  \\\n",
       "196           False          False              True              False   \n",
       "447           False          False              True              False   \n",
       "339           False          False             False              False   \n",
       "464           False          False             False              False   \n",
       "1190          False          False             False              False   \n",
       "\n",
       "      GarageType_Attchd  GarageType_Basment  GarageType_BuiltIn  \\\n",
       "196                True               False               False   \n",
       "447                True               False               False   \n",
       "339                True               False               False   \n",
       "464                True               False               False   \n",
       "1190               True               False               False   \n",
       "\n",
       "      GarageType_CarPort  GarageType_Detchd  \n",
       "196                False              False  \n",
       "447                False              False  \n",
       "339                False              False  \n",
       "464                False              False  \n",
       "1190               False              False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 수치형 변수들 Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#numerical = X_train.select_dtypes(exclude='object').columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_valid_scaled = scaler.transform(X_valid_encoded)\n",
    "test_scaled = scaler.transform(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1205, 28)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1205, 28)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1205, 28), (1205,))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prohe\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.527e+11, tolerance: 7.513e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.0005, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.0005, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.0005, random_state=42)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lasso = Lasso(alpha=0.0005, random_state=42)\n",
    "lasso.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36765.52039384454, 29699.20903511644)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation set 예측 및 평가\n",
    "y_train_pred = lasso.predict(X_train_scaled)\n",
    "y_valid_pred = lasso.predict(X_valid_scaled)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "valid_rmse = mean_squared_error(y_valid, y_valid_pred, squared=False)\n",
    "\n",
    "train_rmse, valid_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이지안 최적화\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "param_bounds = {\n",
    "    'learning_rate' : (0.001, 0.5),\n",
    "    'max_leaves': (2, 1024),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'gamma': (0, 10),\n",
    "    'max_depth': (3, 15),\n",
    "    'min_child_weight': (1, 10),\n",
    "    }\n",
    "\n",
    "def eval_function(max_leaves, learning_rate, n_estimators, gamma, max_depth, min_child_weight):\n",
    "    params = {\n",
    "        'learning_rate' : learning_rate, \n",
    "        'max_leaves': int(max_leaves),\n",
    "        'n_estimators': int(n_estimators),\n",
    "        'gamma': gamma,\n",
    "        'max_depth': int(max_depth),\n",
    "        'min_child_weight': min_child_weight,\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBRegressor(**params, random_state=42)\n",
    "    xgb_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = xgb_model.predict(X_valid_scaled)\n",
    "    valid_rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    return -valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | learni... | max_depth | max_le... | min_ch... | n_esti... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.612e+0\u001b[0m | \u001b[0m3.745    \u001b[0m | \u001b[0m0.4754   \u001b[0m | \u001b[0m11.78    \u001b[0m | \u001b[0m613.8    \u001b[0m | \u001b[0m2.404    \u001b[0m | \u001b[0m240.4    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-2.703e+0\u001b[0m | \u001b[0m0.5808   \u001b[0m | \u001b[0m0.4332   \u001b[0m | \u001b[0m10.21    \u001b[0m | \u001b[0m725.7    \u001b[0m | \u001b[0m1.185    \u001b[0m | \u001b[0m972.9    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-2.371e+0\u001b[0m | \u001b[95m8.324    \u001b[0m | \u001b[95m0.107    \u001b[0m | \u001b[95m5.182    \u001b[0m | \u001b[95m189.4    \u001b[0m | \u001b[95m3.738    \u001b[0m | \u001b[95m572.3    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-2.549e+0\u001b[0m | \u001b[0m4.319    \u001b[0m | \u001b[0m0.1463   \u001b[0m | \u001b[0m10.34    \u001b[0m | \u001b[0m144.6    \u001b[0m | \u001b[0m3.629    \u001b[0m | \u001b[0m429.7    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-2.57e+04\u001b[0m | \u001b[0m4.561    \u001b[0m | \u001b[0m0.3928   \u001b[0m | \u001b[0m5.396    \u001b[0m | \u001b[0m527.5    \u001b[0m | \u001b[0m6.332    \u001b[0m | \u001b[0m141.8    \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m-2.259e+0\u001b[0m | \u001b[95m1.892    \u001b[0m | \u001b[95m0.1454   \u001b[0m | \u001b[95m13.68    \u001b[0m | \u001b[95m178.8    \u001b[0m | \u001b[95m9.306    \u001b[0m | \u001b[95m570.5    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.403e+0\u001b[0m | \u001b[0m4.156    \u001b[0m | \u001b[0m0.259    \u001b[0m | \u001b[0m12.6     \u001b[0m | \u001b[0m180.1    \u001b[0m | \u001b[0m3.888    \u001b[0m | \u001b[0m569.3    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1.072e+0\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.001    \u001b[0m | \u001b[0m10.62    \u001b[0m | \u001b[0m182.6    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m576.0    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-2.412e+0\u001b[0m | \u001b[0m4.065    \u001b[0m | \u001b[0m0.2388   \u001b[0m | \u001b[0m11.55    \u001b[0m | \u001b[0m179.2    \u001b[0m | \u001b[0m7.936    \u001b[0m | \u001b[0m566.9    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-2.582e+0\u001b[0m | \u001b[0m0.64     \u001b[0m | \u001b[0m0.4607   \u001b[0m | \u001b[0m13.33    \u001b[0m | \u001b[0m149.8    \u001b[0m | \u001b[0m2.473    \u001b[0m | \u001b[0m429.3    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.441e+0\u001b[0m | \u001b[0m9.497    \u001b[0m | \u001b[0m0.07829  \u001b[0m | \u001b[0m11.77    \u001b[0m | \u001b[0m176.9    \u001b[0m | \u001b[0m7.476    \u001b[0m | \u001b[0m563.3    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.685e+0\u001b[0m | \u001b[0m2.257    \u001b[0m | \u001b[0m0.4019   \u001b[0m | \u001b[0m7.483    \u001b[0m | \u001b[0m153.6    \u001b[0m | \u001b[0m4.992    \u001b[0m | \u001b[0m427.1    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-2.455e+0\u001b[0m | \u001b[0m1.942    \u001b[0m | \u001b[0m0.253    \u001b[0m | \u001b[0m13.53    \u001b[0m | \u001b[0m176.7    \u001b[0m | \u001b[0m6.556    \u001b[0m | \u001b[0m566.2    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-3.079e+0\u001b[0m | \u001b[0m3.486    \u001b[0m | \u001b[0m0.4266   \u001b[0m | \u001b[0m11.09    \u001b[0m | \u001b[0m186.3    \u001b[0m | \u001b[0m1.152    \u001b[0m | \u001b[0m562.2    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-2.399e+0\u001b[0m | \u001b[0m4.88     \u001b[0m | \u001b[0m0.146    \u001b[0m | \u001b[0m11.51    \u001b[0m | \u001b[0m174.0    \u001b[0m | \u001b[0m8.834    \u001b[0m | \u001b[0m568.8    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-2.625e+0\u001b[0m | \u001b[0m8.605    \u001b[0m | \u001b[0m0.3778   \u001b[0m | \u001b[0m5.349    \u001b[0m | \u001b[0m195.3    \u001b[0m | \u001b[0m6.741    \u001b[0m | \u001b[0m565.5    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-2.562e+0\u001b[0m | \u001b[0m8.536    \u001b[0m | \u001b[0m0.4689   \u001b[0m | \u001b[0m12.02    \u001b[0m | \u001b[0m169.1    \u001b[0m | \u001b[0m3.022    \u001b[0m | \u001b[0m557.8    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-2.68e+04\u001b[0m | \u001b[0m9.189    \u001b[0m | \u001b[0m0.3837   \u001b[0m | \u001b[0m11.85    \u001b[0m | \u001b[0m175.4    \u001b[0m | \u001b[0m1.489    \u001b[0m | \u001b[0m568.7    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-2.682e+0\u001b[0m | \u001b[0m2.079    \u001b[0m | \u001b[0m0.3481   \u001b[0m | \u001b[0m5.584    \u001b[0m | \u001b[0m177.9    \u001b[0m | \u001b[0m2.649    \u001b[0m | \u001b[0m558.0    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-2.534e+0\u001b[0m | \u001b[0m7.423    \u001b[0m | \u001b[0m0.3887   \u001b[0m | \u001b[0m9.61     \u001b[0m | \u001b[0m151.3    \u001b[0m | \u001b[0m2.324    \u001b[0m | \u001b[0m434.8    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-2.523e+0\u001b[0m | \u001b[0m5.435    \u001b[0m | \u001b[0m0.3369   \u001b[0m | \u001b[0m4.425    \u001b[0m | \u001b[0m178.0    \u001b[0m | \u001b[0m8.449    \u001b[0m | \u001b[0m563.8    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-2.538e+0\u001b[0m | \u001b[0m3.844    \u001b[0m | \u001b[0m0.3971   \u001b[0m | \u001b[0m3.249    \u001b[0m | \u001b[0m198.5    \u001b[0m | \u001b[0m3.431    \u001b[0m | \u001b[0m571.5    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-2.314e+0\u001b[0m | \u001b[0m0.5874   \u001b[0m | \u001b[0m0.1401   \u001b[0m | \u001b[0m11.26    \u001b[0m | \u001b[0m170.3    \u001b[0m | \u001b[0m9.378    \u001b[0m | \u001b[0m559.8    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-2.923e+0\u001b[0m | \u001b[0m8.801    \u001b[0m | \u001b[0m0.4115   \u001b[0m | \u001b[0m3.116    \u001b[0m | \u001b[0m199.7    \u001b[0m | \u001b[0m1.768    \u001b[0m | \u001b[0m577.6    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-2.5e+04 \u001b[0m | \u001b[0m2.583    \u001b[0m | \u001b[0m0.2696   \u001b[0m | \u001b[0m9.231    \u001b[0m | \u001b[0m150.8    \u001b[0m | \u001b[0m9.681    \u001b[0m | \u001b[0m438.3    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-2.558e+0\u001b[0m | \u001b[0m8.347    \u001b[0m | \u001b[0m0.2112   \u001b[0m | \u001b[0m12.09    \u001b[0m | \u001b[0m146.7    \u001b[0m | \u001b[0m8.748    \u001b[0m | \u001b[0m441.5    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-1.087e+0\u001b[0m | \u001b[0m5.129    \u001b[0m | \u001b[0m0.001    \u001b[0m | \u001b[0m8.14     \u001b[0m | \u001b[0m171.5    \u001b[0m | \u001b[0m6.051    \u001b[0m | \u001b[0m562.7    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-2.612e+0\u001b[0m | \u001b[0m6.92     \u001b[0m | \u001b[0m0.3161   \u001b[0m | \u001b[0m9.935    \u001b[0m | \u001b[0m183.3    \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m570.8    \u001b[0m |\n",
      "| \u001b[95m29       \u001b[0m | \u001b[95m-2.25e+04\u001b[0m | \u001b[95m3.857    \u001b[0m | \u001b[95m0.1421   \u001b[0m | \u001b[95m6.65     \u001b[0m | \u001b[95m201.3    \u001b[0m | \u001b[95m5.717    \u001b[0m | \u001b[95m569.0    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-2.321e+0\u001b[0m | \u001b[0m3.713    \u001b[0m | \u001b[0m0.1204   \u001b[0m | \u001b[0m7.936    \u001b[0m | \u001b[0m523.9    \u001b[0m | \u001b[0m7.512    \u001b[0m | \u001b[0m137.4    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-2.344e+0\u001b[0m | \u001b[0m7.877    \u001b[0m | \u001b[0m0.2834   \u001b[0m | \u001b[0m7.232    \u001b[0m | \u001b[0m179.5    \u001b[0m | \u001b[0m7.521    \u001b[0m | \u001b[0m565.4    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-2.336e+0\u001b[0m | \u001b[0m3.726    \u001b[0m | \u001b[0m0.3274   \u001b[0m | \u001b[0m6.526    \u001b[0m | \u001b[0m197.4    \u001b[0m | \u001b[0m3.465    \u001b[0m | \u001b[0m575.0    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-2.477e+0\u001b[0m | \u001b[0m4.501    \u001b[0m | \u001b[0m0.3858   \u001b[0m | \u001b[0m13.92    \u001b[0m | \u001b[0m173.7    \u001b[0m | \u001b[0m9.364    \u001b[0m | \u001b[0m573.1    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-2.621e+0\u001b[0m | \u001b[0m3.516    \u001b[0m | \u001b[0m0.1392   \u001b[0m | \u001b[0m6.126    \u001b[0m | \u001b[0m202.4    \u001b[0m | \u001b[0m1.876    \u001b[0m | \u001b[0m567.7    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-2.417e+0\u001b[0m | \u001b[0m3.176    \u001b[0m | \u001b[0m0.2997   \u001b[0m | \u001b[0m10.09    \u001b[0m | \u001b[0m149.5    \u001b[0m | \u001b[0m5.786    \u001b[0m | \u001b[0m433.1    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-2.837e+0\u001b[0m | \u001b[0m1.132    \u001b[0m | \u001b[0m0.4172   \u001b[0m | \u001b[0m10.01    \u001b[0m | \u001b[0m153.0    \u001b[0m | \u001b[0m1.622    \u001b[0m | \u001b[0m437.9    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-2.255e+0\u001b[0m | \u001b[0m5.139    \u001b[0m | \u001b[0m0.2606   \u001b[0m | \u001b[0m6.427    \u001b[0m | \u001b[0m526.7    \u001b[0m | \u001b[0m3.332    \u001b[0m | \u001b[0m136.4    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-2.493e+0\u001b[0m | \u001b[0m5.923    \u001b[0m | \u001b[0m0.09551  \u001b[0m | \u001b[0m11.06    \u001b[0m | \u001b[0m201.2    \u001b[0m | \u001b[0m2.616    \u001b[0m | \u001b[0m573.2    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-2.712e+0\u001b[0m | \u001b[0m9.315    \u001b[0m | \u001b[0m0.3529   \u001b[0m | \u001b[0m13.52    \u001b[0m | \u001b[0m179.9    \u001b[0m | \u001b[0m8.862    \u001b[0m | \u001b[0m567.0    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-2.638e+0\u001b[0m | \u001b[0m6.294    \u001b[0m | \u001b[0m0.4654   \u001b[0m | \u001b[0m11.06    \u001b[0m | \u001b[0m520.7    \u001b[0m | \u001b[0m3.12     \u001b[0m | \u001b[0m137.1    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-9.335e+0\u001b[0m | \u001b[0m4.203    \u001b[0m | \u001b[0m0.005314 \u001b[0m | \u001b[0m3.735    \u001b[0m | \u001b[0m519.5    \u001b[0m | \u001b[0m9.735    \u001b[0m | \u001b[0m137.5    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-2.708e+0\u001b[0m | \u001b[0m8.109    \u001b[0m | \u001b[0m0.4514   \u001b[0m | \u001b[0m5.547    \u001b[0m | \u001b[0m201.8    \u001b[0m | \u001b[0m2.762    \u001b[0m | \u001b[0m573.1    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-2.394e+0\u001b[0m | \u001b[0m3.894    \u001b[0m | \u001b[0m0.2649   \u001b[0m | \u001b[0m10.03    \u001b[0m | \u001b[0m526.0    \u001b[0m | \u001b[0m5.603    \u001b[0m | \u001b[0m132.3    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-2.614e+0\u001b[0m | \u001b[0m3.307    \u001b[0m | \u001b[0m0.4462   \u001b[0m | \u001b[0m5.523    \u001b[0m | \u001b[0m193.8    \u001b[0m | \u001b[0m7.22     \u001b[0m | \u001b[0m570.2    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-2.305e+0\u001b[0m | \u001b[0m3.391    \u001b[0m | \u001b[0m0.08403  \u001b[0m | \u001b[0m7.772    \u001b[0m | \u001b[0m197.2    \u001b[0m | \u001b[0m2.518    \u001b[0m | \u001b[0m567.1    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-2.352e+0\u001b[0m | \u001b[0m4.551    \u001b[0m | \u001b[0m0.05612  \u001b[0m | \u001b[0m13.27    \u001b[0m | \u001b[0m199.9    \u001b[0m | \u001b[0m6.508    \u001b[0m | \u001b[0m567.8    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-2.43e+04\u001b[0m | \u001b[0m7.348    \u001b[0m | \u001b[0m0.1946   \u001b[0m | \u001b[0m11.46    \u001b[0m | \u001b[0m194.4    \u001b[0m | \u001b[0m5.547    \u001b[0m | \u001b[0m571.5    \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-2.539e+0\u001b[0m | \u001b[0m2.225    \u001b[0m | \u001b[0m0.3666   \u001b[0m | \u001b[0m8.332    \u001b[0m | \u001b[0m529.9    \u001b[0m | \u001b[0m3.864    \u001b[0m | \u001b[0m137.6    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-2.446e+0\u001b[0m | \u001b[0m6.992    \u001b[0m | \u001b[0m0.2432   \u001b[0m | \u001b[0m12.86    \u001b[0m | \u001b[0m200.6    \u001b[0m | \u001b[0m9.111    \u001b[0m | \u001b[0m573.1    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-2.469e+0\u001b[0m | \u001b[0m7.85     \u001b[0m | \u001b[0m0.01046  \u001b[0m | \u001b[0m13.73    \u001b[0m | \u001b[0m151.2    \u001b[0m | \u001b[0m9.194    \u001b[0m | \u001b[0m433.8    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-2.444e+0\u001b[0m | \u001b[0m8.309    \u001b[0m | \u001b[0m0.1846   \u001b[0m | \u001b[0m9.482    \u001b[0m | \u001b[0m154.3    \u001b[0m | \u001b[0m8.846    \u001b[0m | \u001b[0m441.5    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-2.507e+0\u001b[0m | \u001b[0m0.1609   \u001b[0m | \u001b[0m0.2174   \u001b[0m | \u001b[0m7.341    \u001b[0m | \u001b[0m197.7    \u001b[0m | \u001b[0m7.613    \u001b[0m | \u001b[0m567.1    \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-2.373e+0\u001b[0m | \u001b[0m8.392    \u001b[0m | \u001b[0m0.2113   \u001b[0m | \u001b[0m9.083    \u001b[0m | \u001b[0m531.8    \u001b[0m | \u001b[0m8.215    \u001b[0m | \u001b[0m133.9    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-2.565e+0\u001b[0m | \u001b[0m7.742    \u001b[0m | \u001b[0m0.243    \u001b[0m | \u001b[0m12.16    \u001b[0m | \u001b[0m157.8    \u001b[0m | \u001b[0m6.298    \u001b[0m | \u001b[0m433.8    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-2.349e+0\u001b[0m | \u001b[0m9.172    \u001b[0m | \u001b[0m0.3121   \u001b[0m | \u001b[0m6.654    \u001b[0m | \u001b[0m529.3    \u001b[0m | \u001b[0m3.119    \u001b[0m | \u001b[0m131.2    \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "optimizer = BayesianOptimization(f=eval_function, pbounds=param_bounds, random_state=42)\n",
    "optimizer.maximize(init_points=5, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=3.857417634845203, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.14205296580247595, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=201,\n",
       "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=569, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=3.857417634845203, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.14205296580247595, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=201,\n",
       "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=569, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=3.857417634845203, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.14205296580247595, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=201,\n",
       "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=569, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적화된 하이퍼파라미터로 모델 재학습\n",
    "best_params = {\n",
    "    'n_estimators': round(optimizer.max['params']['n_estimators']),\n",
    "    'max_depth': round(optimizer.max['params']['max_depth']),\n",
    "    'max_leaves': round(optimizer.max['params']['max_leaves']),\n",
    "    'min_child_weight': round(optimizer.max['params']['min_child_weight']),\n",
    "    'learning_rate': optimizer.max['params']['learning_rate'],\n",
    "    'gamma': optimizer.max['params']['gamma'],\n",
    "}\n",
    "\n",
    "best_xgb = XGBRegressor(**best_params, random_state=42)\n",
    "best_xgb.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467.0642663695416, 22815.096664588735)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation set 예측 및 평가\n",
    "y_train_pred = best_xgb.predict(X_train_scaled)\n",
    "y_valid_pred = best_xgb.predict(X_valid_scaled)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "valid_rmse = mean_squared_error(y_valid, y_valid_pred, squared=False)\n",
    "\n",
    "train_rmse, valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929806845324563"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 결정계수 확인\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이지안 최적화\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "param_bounds = {\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3, 15),\n",
    "    'num_leaves': (20, 300),\n",
    "    'min_child_samples': (10, 30),\n",
    "    'learning_rate': (0.001, 0.5),\n",
    "}\n",
    "\n",
    "def eval_function(n_estimators, max_depth, num_leaves, min_child_samples, learning_rate):\n",
    "    params = {\n",
    "        'n_estimators': int(n_estimators),\n",
    "        'max_depth': int(max_depth),\n",
    "        'num_leaves': int(num_leaves),\n",
    "        'min_child_samples': int(min_child_samples),\n",
    "        'learning_rate': learning_rate,\n",
    "    }\n",
    "    lgbm = LGBMRegressor(**params, metric='RMSE', random_state=42, verbose=0)\n",
    "\n",
    "    lgbm.fit(X_train_scaled, y_train)\n",
    "    y_pred = lgbm.predict(X_valid_scaled)\n",
    "    valid_rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    return -valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_ch... | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.484e+0\u001b[0m | \u001b[0m0.1879   \u001b[0m | \u001b[0m14.41    \u001b[0m | \u001b[0m24.64    \u001b[0m | \u001b[0m638.8    \u001b[0m | \u001b[0m63.69    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-2.343e+0\u001b[0m | \u001b[95m0.07884  \u001b[0m | \u001b[95m3.697    \u001b[0m | \u001b[95m27.32    \u001b[0m | \u001b[95m641.0    \u001b[0m | \u001b[95m218.3    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-2.374e+0\u001b[0m | \u001b[0m0.01127  \u001b[0m | \u001b[0m14.64    \u001b[0m | \u001b[0m26.65    \u001b[0m | \u001b[0m291.1    \u001b[0m | \u001b[0m70.91    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-2.617e+0\u001b[0m | \u001b[0m0.09252  \u001b[0m | \u001b[0m6.651    \u001b[0m | \u001b[0m20.5     \u001b[0m | \u001b[0m488.8    \u001b[0m | \u001b[0m101.5    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-2.64e+04\u001b[0m | \u001b[0m0.3063   \u001b[0m | \u001b[0m4.674    \u001b[0m | \u001b[0m15.84    \u001b[0m | \u001b[0m429.7    \u001b[0m | \u001b[0m147.7    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-2.565e+0\u001b[0m | \u001b[0m0.1916   \u001b[0m | \u001b[0m4.61     \u001b[0m | \u001b[0m19.56    \u001b[0m | \u001b[0m648.0    \u001b[0m | \u001b[0m213.6    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.485e+0\u001b[0m | \u001b[0m0.4533   \u001b[0m | \u001b[0m4.264    \u001b[0m | \u001b[0m12.95    \u001b[0m | \u001b[0m932.8    \u001b[0m | \u001b[0m235.8    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-2.6e+04 \u001b[0m | \u001b[0m0.2924   \u001b[0m | \u001b[0m3.573    \u001b[0m | \u001b[0m10.72    \u001b[0m | \u001b[0m194.1    \u001b[0m | \u001b[0m85.3     \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-2.436e+0\u001b[0m | \u001b[0m0.2348   \u001b[0m | \u001b[0m14.92    \u001b[0m | \u001b[0m28.44    \u001b[0m | \u001b[0m488.6    \u001b[0m | \u001b[0m108.3    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-2.707e+0\u001b[0m | \u001b[0m0.4446   \u001b[0m | \u001b[0m14.22    \u001b[0m | \u001b[0m26.0     \u001b[0m | \u001b[0m492.0    \u001b[0m | \u001b[0m107.9    \u001b[0m |\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m-2.261e+0\u001b[0m | \u001b[95m0.2461   \u001b[0m | \u001b[95m6.069    \u001b[0m | \u001b[95m24.7     \u001b[0m | \u001b[95m636.2    \u001b[0m | \u001b[95m243.5    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.519e+0\u001b[0m | \u001b[0m0.03866  \u001b[0m | \u001b[0m12.74    \u001b[0m | \u001b[0m19.33    \u001b[0m | \u001b[0m375.2    \u001b[0m | \u001b[0m103.6    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-2.478e+0\u001b[0m | \u001b[0m0.04217  \u001b[0m | \u001b[0m13.85    \u001b[0m | \u001b[0m21.87    \u001b[0m | \u001b[0m774.8    \u001b[0m | \u001b[0m229.5    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-2.6e+04 \u001b[0m | \u001b[0m0.3643   \u001b[0m | \u001b[0m11.01    \u001b[0m | \u001b[0m29.89    \u001b[0m | \u001b[0m465.9    \u001b[0m | \u001b[0m170.8    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-2.634e+0\u001b[0m | \u001b[0m0.06766  \u001b[0m | \u001b[0m11.85    \u001b[0m | \u001b[0m16.03    \u001b[0m | \u001b[0m270.6    \u001b[0m | \u001b[0m83.52    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-2.708e+0\u001b[0m | \u001b[0m0.1364   \u001b[0m | \u001b[0m10.82    \u001b[0m | \u001b[0m11.24    \u001b[0m | \u001b[0m772.4    \u001b[0m | \u001b[0m288.6    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-2.494e+0\u001b[0m | \u001b[0m0.08275  \u001b[0m | \u001b[0m4.213    \u001b[0m | \u001b[0m14.76    \u001b[0m | \u001b[0m921.0    \u001b[0m | \u001b[0m242.6    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-2.711e+0\u001b[0m | \u001b[0m0.3889   \u001b[0m | \u001b[0m7.291    \u001b[0m | \u001b[0m26.75    \u001b[0m | \u001b[0m941.2    \u001b[0m | \u001b[0m65.66    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-2.468e+0\u001b[0m | \u001b[0m0.2533   \u001b[0m | \u001b[0m9.14     \u001b[0m | \u001b[0m25.83    \u001b[0m | \u001b[0m397.4    \u001b[0m | \u001b[0m278.3    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-2.909e+0\u001b[0m | \u001b[0m0.4321   \u001b[0m | \u001b[0m9.865    \u001b[0m | \u001b[0m18.33    \u001b[0m | \u001b[0m264.9    \u001b[0m | \u001b[0m98.81    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-2.704e+0\u001b[0m | \u001b[0m0.3128   \u001b[0m | \u001b[0m12.16    \u001b[0m | \u001b[0m17.67    \u001b[0m | \u001b[0m271.0    \u001b[0m | \u001b[0m254.5    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-2.662e+0\u001b[0m | \u001b[0m0.2835   \u001b[0m | \u001b[0m3.626    \u001b[0m | \u001b[0m17.28    \u001b[0m | \u001b[0m246.9    \u001b[0m | \u001b[0m63.38    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-2.468e+0\u001b[0m | \u001b[0m0.2685   \u001b[0m | \u001b[0m12.62    \u001b[0m | \u001b[0m26.52    \u001b[0m | \u001b[0m594.4    \u001b[0m | \u001b[0m172.9    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-2.587e+0\u001b[0m | \u001b[0m0.03525  \u001b[0m | \u001b[0m3.831    \u001b[0m | \u001b[0m13.07    \u001b[0m | \u001b[0m404.4    \u001b[0m | \u001b[0m124.5    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-2.51e+04\u001b[0m | \u001b[0m0.06574  \u001b[0m | \u001b[0m11.8     \u001b[0m | \u001b[0m25.08    \u001b[0m | \u001b[0m398.7    \u001b[0m | \u001b[0m278.8    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-2.428e+0\u001b[0m | \u001b[0m0.05962  \u001b[0m | \u001b[0m9.366    \u001b[0m | \u001b[0m22.83    \u001b[0m | \u001b[0m775.9    \u001b[0m | \u001b[0m227.2    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-2.538e+0\u001b[0m | \u001b[0m0.2968   \u001b[0m | \u001b[0m9.003    \u001b[0m | \u001b[0m21.63    \u001b[0m | \u001b[0m636.1    \u001b[0m | \u001b[0m245.1    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-2.53e+04\u001b[0m | \u001b[0m0.2296   \u001b[0m | \u001b[0m9.911    \u001b[0m | \u001b[0m26.21    \u001b[0m | \u001b[0m593.6    \u001b[0m | \u001b[0m174.0    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-2.539e+0\u001b[0m | \u001b[0m0.2827   \u001b[0m | \u001b[0m13.74    \u001b[0m | \u001b[0m21.81    \u001b[0m | \u001b[0m291.9    \u001b[0m | \u001b[0m70.43    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-2.594e+0\u001b[0m | \u001b[0m0.421    \u001b[0m | \u001b[0m4.105    \u001b[0m | \u001b[0m22.76    \u001b[0m | \u001b[0m641.0    \u001b[0m | \u001b[0m218.7    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-2.654e+0\u001b[0m | \u001b[0m0.002565 \u001b[0m | \u001b[0m5.938    \u001b[0m | \u001b[0m11.68    \u001b[0m | \u001b[0m934.0    \u001b[0m | \u001b[0m232.3    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-2.525e+0\u001b[0m | \u001b[0m0.275    \u001b[0m | \u001b[0m3.783    \u001b[0m | \u001b[0m21.18    \u001b[0m | \u001b[0m635.9    \u001b[0m | \u001b[0m246.0    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-2.562e+0\u001b[0m | \u001b[0m0.141    \u001b[0m | \u001b[0m7.967    \u001b[0m | \u001b[0m21.89    \u001b[0m | \u001b[0m633.4    \u001b[0m | \u001b[0m244.6    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-2.31e+04\u001b[0m | \u001b[0m0.3169   \u001b[0m | \u001b[0m12.67    \u001b[0m | \u001b[0m22.87    \u001b[0m | \u001b[0m637.7    \u001b[0m | \u001b[0m63.39    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-2.338e+0\u001b[0m | \u001b[0m0.2194   \u001b[0m | \u001b[0m11.33    \u001b[0m | \u001b[0m23.51    \u001b[0m | \u001b[0m638.1    \u001b[0m | \u001b[0m63.61    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-2.512e+0\u001b[0m | \u001b[0m0.04097  \u001b[0m | \u001b[0m6.984    \u001b[0m | \u001b[0m23.47    \u001b[0m | \u001b[0m634.7    \u001b[0m | \u001b[0m240.9    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-2.488e+0\u001b[0m | \u001b[0m0.009749 \u001b[0m | \u001b[0m14.33    \u001b[0m | \u001b[0m19.22    \u001b[0m | \u001b[0m637.0    \u001b[0m | \u001b[0m61.13    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-2.505e+0\u001b[0m | \u001b[0m0.4193   \u001b[0m | \u001b[0m6.671    \u001b[0m | \u001b[0m24.27    \u001b[0m | \u001b[0m636.3    \u001b[0m | \u001b[0m243.8    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-2.43e+04\u001b[0m | \u001b[0m0.1337   \u001b[0m | \u001b[0m14.57    \u001b[0m | \u001b[0m29.41    \u001b[0m | \u001b[0m490.4    \u001b[0m | \u001b[0m109.1    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-2.666e+0\u001b[0m | \u001b[0m0.2228   \u001b[0m | \u001b[0m12.08    \u001b[0m | \u001b[0m21.08    \u001b[0m | \u001b[0m640.6    \u001b[0m | \u001b[0m61.31    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-2.448e+0\u001b[0m | \u001b[0m0.4092   \u001b[0m | \u001b[0m5.626    \u001b[0m | \u001b[0m24.65    \u001b[0m | \u001b[0m639.3    \u001b[0m | \u001b[0m244.4    \u001b[0m |\n",
      "| \u001b[95m42       \u001b[0m | \u001b[95m-2.205e+0\u001b[0m | \u001b[95m0.2851   \u001b[0m | \u001b[95m8.431    \u001b[0m | \u001b[95m23.99    \u001b[0m | \u001b[95m396.4    \u001b[0m | \u001b[95m280.4    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-2.453e+0\u001b[0m | \u001b[0m0.4026   \u001b[0m | \u001b[0m8.892    \u001b[0m | \u001b[0m23.96    \u001b[0m | \u001b[0m398.8    \u001b[0m | \u001b[0m283.4    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-2.516e+0\u001b[0m | \u001b[0m0.2387   \u001b[0m | \u001b[0m4.971    \u001b[0m | \u001b[0m24.17    \u001b[0m | \u001b[0m638.6    \u001b[0m | \u001b[0m241.0    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-2.366e+0\u001b[0m | \u001b[0m0.02714  \u001b[0m | \u001b[0m12.64    \u001b[0m | \u001b[0m23.59    \u001b[0m | \u001b[0m638.3    \u001b[0m | \u001b[0m63.6     \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-2.403e+0\u001b[0m | \u001b[0m0.1864   \u001b[0m | \u001b[0m9.109    \u001b[0m | \u001b[0m23.89    \u001b[0m | \u001b[0m778.6    \u001b[0m | \u001b[0m225.6    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-2.568e+0\u001b[0m | \u001b[0m0.3039   \u001b[0m | \u001b[0m8.011    \u001b[0m | \u001b[0m26.54    \u001b[0m | \u001b[0m636.3    \u001b[0m | \u001b[0m244.1    \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-2.632e+0\u001b[0m | \u001b[0m0.298    \u001b[0m | \u001b[0m10.41    \u001b[0m | \u001b[0m25.49    \u001b[0m | \u001b[0m636.4    \u001b[0m | \u001b[0m63.2     \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-2.643e+0\u001b[0m | \u001b[0m0.4165   \u001b[0m | \u001b[0m6.576    \u001b[0m | \u001b[0m26.31    \u001b[0m | \u001b[0m639.1    \u001b[0m | \u001b[0m246.8    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-2.802e+0\u001b[0m | \u001b[0m0.4648   \u001b[0m | \u001b[0m11.77    \u001b[0m | \u001b[0m26.38    \u001b[0m | \u001b[0m595.5    \u001b[0m | \u001b[0m173.3    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-2.422e+0\u001b[0m | \u001b[0m0.01211  \u001b[0m | \u001b[0m6.612    \u001b[0m | \u001b[0m29.64    \u001b[0m | \u001b[0m640.2    \u001b[0m | \u001b[0m217.3    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-2.701e+0\u001b[0m | \u001b[0m0.2024   \u001b[0m | \u001b[0m13.25    \u001b[0m | \u001b[0m17.68    \u001b[0m | \u001b[0m637.5    \u001b[0m | \u001b[0m59.82    \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-2.358e+0\u001b[0m | \u001b[0m0.04808  \u001b[0m | \u001b[0m12.86    \u001b[0m | \u001b[0m27.27    \u001b[0m | \u001b[0m593.5    \u001b[0m | \u001b[0m174.6    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-2.423e+0\u001b[0m | \u001b[0m0.02358  \u001b[0m | \u001b[0m4.945    \u001b[0m | \u001b[0m10.61    \u001b[0m | \u001b[0m931.6    \u001b[0m | \u001b[0m235.5    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-2.533e+0\u001b[0m | \u001b[0m0.3725   \u001b[0m | \u001b[0m8.775    \u001b[0m | \u001b[0m22.53    \u001b[0m | \u001b[0m399.5    \u001b[0m | \u001b[0m282.4    \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "optimizer = BayesianOptimization(f=eval_function, pbounds=param_bounds, random_state=42)\n",
    "optimizer.maximize(init_points=5, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.2850573982846811, max_depth=8, metric=&#x27;RMSE&#x27;,\n",
       "              min_child_samples=24, n_estimators=396, num_leaves=280,\n",
       "              random_state=42, verbose=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.2850573982846811, max_depth=8, metric=&#x27;RMSE&#x27;,\n",
       "              min_child_samples=24, n_estimators=396, num_leaves=280,\n",
       "              random_state=42, verbose=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(learning_rate=0.2850573982846811, max_depth=8, metric='RMSE',\n",
       "              min_child_samples=24, n_estimators=396, num_leaves=280,\n",
       "              random_state=42, verbose=0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적화된 하이퍼파라미터로 모델 재학습\n",
    "best_params = {\n",
    "    'n_estimators': round(optimizer.max['params']['n_estimators']),\n",
    "    'max_depth': round(optimizer.max['params']['max_depth']),\n",
    "    'num_leaves': round(optimizer.max['params']['num_leaves']),\n",
    "    'min_child_samples': round(optimizer.max['params']['min_child_samples']),\n",
    "    'learning_rate': optimizer.max['params']['learning_rate'],\n",
    "}\n",
    "\n",
    "best_lgbm = LGBMRegressor(**best_params, metric='RMSE', random_state=42, verbose=0)\n",
    "best_lgbm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2867.2336439159444, 24445.91374360593)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation set 예측 및 평가\n",
    "y_train_pred = best_lgbm.predict(X_train_scaled)\n",
    "y_valid_pred = best_lgbm.predict(X_valid_scaled)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "valid_rmse = mean_squared_error(y_valid, y_valid_pred, squared=False)\n",
    "\n",
    "train_rmse, valid_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "param_bounds = {\n",
    "    'C': (0.1, 10),\n",
    "    'gamma': (0.1, 10),\n",
    "    }\n",
    "\n",
    "def eval_function(C, gamma):\n",
    "\n",
    "    svr = SVR(kernel='rbf', C=C, gamma=gamma)\n",
    "    svr.fit(X_train_scaled, y_train)\n",
    "    y_pred = svr.predict(X_valid_scaled)\n",
    "    valid_rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    return -valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m3.808    \u001b[0m | \u001b[0m9.512    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-7.02e+04\u001b[0m | \u001b[95m7.347    \u001b[0m | \u001b[95m6.027    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m1.645    \u001b[0m | \u001b[0m1.644    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m0.675    \u001b[0m | \u001b[0m8.675    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m6.051    \u001b[0m | \u001b[0m7.11     \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m-7.02e+04\u001b[0m | \u001b[95m8.587    \u001b[0m | \u001b[95m1.981    \u001b[0m |\n",
      "| \u001b[95m7        \u001b[0m | \u001b[95m-6.995e+0\u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m0.1      \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-7.018e+0\u001b[0m | \u001b[0m9.929    \u001b[0m | \u001b[0m0.5254   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m0.1559   \u001b[0m | \u001b[0m4.691    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m6.709    \u001b[0m | \u001b[0m6.458    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m0.4215   \u001b[0m | \u001b[0m2.231    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m4.474    \u001b[0m | \u001b[0m8.261    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m0.2843   \u001b[0m | \u001b[0m4.439    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m4.012    \u001b[0m | \u001b[0m4.925    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-7.01e+04\u001b[0m | \u001b[0m9.986    \u001b[0m | \u001b[0m0.2125   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m6.08     \u001b[0m | \u001b[0m1.602    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-7.005e+0\u001b[0m | \u001b[0m9.881    \u001b[0m | \u001b[0m0.158    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-6.997e+0\u001b[0m | \u001b[0m9.928    \u001b[0m | \u001b[0m0.1091   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-6.997e+0\u001b[0m | \u001b[0m9.684    \u001b[0m | \u001b[0m0.1069   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-7.004e+0\u001b[0m | \u001b[0m9.861    \u001b[0m | \u001b[0m0.1521   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-7.006e+0\u001b[0m | \u001b[0m9.418    \u001b[0m | \u001b[0m0.1626   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-7.017e+0\u001b[0m | \u001b[0m9.526    \u001b[0m | \u001b[0m0.4108   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m8.21     \u001b[0m | \u001b[0m6.84     \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m5.071    \u001b[0m | \u001b[0m6.752    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-7.013e+0\u001b[0m | \u001b[0m9.031    \u001b[0m | \u001b[0m0.2612   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-7.008e+0\u001b[0m | \u001b[0m9.58     \u001b[0m | \u001b[0m0.1895   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m9.074    \u001b[0m | \u001b[0m9.907    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-6.999e+0\u001b[0m | \u001b[0m8.317    \u001b[0m | \u001b[0m0.1034   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m6.516    \u001b[0m | \u001b[0m1.26     \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-7.012e+0\u001b[0m | \u001b[0m8.195    \u001b[0m | \u001b[0m0.2227   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-7.001e+0\u001b[0m | \u001b[0m8.525    \u001b[0m | \u001b[0m0.1215   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m3.693    \u001b[0m | \u001b[0m0.7506   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m8.197    \u001b[0m | \u001b[0m2.237    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m9.208    \u001b[0m | \u001b[0m8.012    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-7.019e+0\u001b[0m | \u001b[0m7.921    \u001b[0m | \u001b[0m0.8379   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-7.012e+0\u001b[0m | \u001b[0m8.429    \u001b[0m | \u001b[0m0.2152   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-7.012e+0\u001b[0m | \u001b[0m8.699    \u001b[0m | \u001b[0m0.2187   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-6.999e+0\u001b[0m | \u001b[0m8.391    \u001b[0m | \u001b[0m0.106    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-6.996e+0\u001b[0m | \u001b[0m9.213    \u001b[0m | \u001b[0m0.1017   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m1.581    \u001b[0m | \u001b[0m4.564    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m9.971    \u001b[0m | \u001b[0m4.522    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m8.865    \u001b[0m | \u001b[0m1.585    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m6.274    \u001b[0m | \u001b[0m3.141    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-7.012e+0\u001b[0m | \u001b[0m9.237    \u001b[0m | \u001b[0m0.2294   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m8.611    \u001b[0m | \u001b[0m2.498    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-7.017e+0\u001b[0m | \u001b[0m8.067    \u001b[0m | \u001b[0m0.3814   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-6.997e+0\u001b[0m | \u001b[0m9.046    \u001b[0m | \u001b[0m0.101    \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m3.856    \u001b[0m | \u001b[0m9.416    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m6.601    \u001b[0m | \u001b[0m8.698    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m2.378    \u001b[0m | \u001b[0m6.92     \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m3.487    \u001b[0m | \u001b[0m2.846    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-6.997e+0\u001b[0m | \u001b[0m9.125    \u001b[0m | \u001b[0m0.1056   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-6.998e+0\u001b[0m | \u001b[0m8.883    \u001b[0m | \u001b[0m0.1088   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-7.02e+04\u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-6.997e+0\u001b[0m | \u001b[0m8.877    \u001b[0m | \u001b[0m0.1031   \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "optimizer = BayesianOptimization(f=eval_function, pbounds=param_bounds, random_state=42)\n",
    "optimizer.maximize(init_points=5, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(C=10.0, gamma=0.10000000000000009)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=10.0, gamma=0.10000000000000009)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(C=10.0, gamma=0.10000000000000009)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적화된 하이퍼파라미터로 모델 재학습\n",
    "best_params = optimizer.max['params']\n",
    "\n",
    "best_svr = SVR(**best_params, kernel='rbf')\n",
    "best_svr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80617.07110639139, 69945.50159339218)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation set 예측 및 평가\n",
    "y_train_pred = best_svr.predict(X_train_scaled)\n",
    "y_valid_pred = best_svr.predict(X_valid_scaled)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "valid_rmse = mean_squared_error(y_valid, y_valid_pred, squared=False)\n",
    "\n",
    "train_rmse, valid_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([132941.92 , 123052.84 , 152929.67 , 130510.01 ,  98148.12 ,\n",
       "       170934.03 , 202057.88 ,  83002.945, 232649.94 , 139623.98 ,\n",
       "       208249.11 , 148903.05 , 267677.03 , 106831.47 , 293492.66 ,\n",
       "       203468.89 , 222260.3  , 178613.6  , 154359.06 , 208637.66 ,\n",
       "       151145.6  , 429144.28 , 109550.56 , 369975.03 , 242341.   ,\n",
       "       245138.42 , 180324.77 , 233111.   , 214289.83 , 195294.52 ,\n",
       "       182666.7  , 220972.06 , 338179.38 , 213143.97 , 216900.95 ,\n",
       "       160156.44 , 146456.27 , 166782.42 , 177528.83 , 142751.97 ,\n",
       "       158735.58 , 295022.75 , 286409.97 , 107031.06 , 235221.3  ,\n",
       "       179800.7  , 167392.75 , 194821.86 , 195435.7  , 139130.52 ,\n",
       "       316262.25 , 199738.94 , 202994.53 , 121208.125,  94726.05 ,\n",
       "       248067.14 , 670864.9  , 134384.61 , 187254.36 , 104968.87 ,\n",
       "       195271.22 , 143478.27 , 162493.73 , 142304.94 , 181751.8  ,\n",
       "       225331.16 , 174996.   , 183069.83 , 153104.   , 121217.914,\n",
       "       223515.22 , 131296.58 , 152384.53 , 160896.69 , 270278.56 ,\n",
       "       182235.89 , 333752.06 , 415674.9  , 113097.74 , 178477.55 ,\n",
       "       268578.22 , 169225.58 , 377102.97 , 184911.98 , 211903.1  ,\n",
       "       133754.42 , 169975.27 , 150592.9  , 201034.44 , 217940.1  ,\n",
       "       126694.98 , 145837.19 , 266926.3  , 137960.75 ,  97761.16 ,\n",
       "       155855.08 ,  68315.72 , 227659.56 , 157075.84 , 150380.53 ,\n",
       "       105172.16 , 168924.95 , 340148.62 , 124385.7  , 170587.14 ,\n",
       "       150867.28 , 137713.33 , 215457.11 , 144134.38 ,  64616.605,\n",
       "       190933.44 , 159915.58 , 185198.33 , 148246.58 ,  82694.22 ,\n",
       "       267883.56 , 129239.45 , 202988.   ,  87817.484, 149189.75 ,\n",
       "       136541.61 , 145942.23 , 114745.89 , 271976.88 , 123052.84 ,\n",
       "       304470.06 , 161278.55 ,  86469.62 , 103392.53 , 131734.72 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종 모델(XGBRegressor)로 test set 예측\n",
    "test_pred = best_xgb.predict(test_scaled)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 파일 생성\n",
    "submission_origin = pd.read_csv(file_path+'\\submission.csv')\n",
    "submission = submission_origin.copy()\n",
    "submission['SalePrice'] = test_pred\n",
    "submission.to_csv('baseline_model.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
